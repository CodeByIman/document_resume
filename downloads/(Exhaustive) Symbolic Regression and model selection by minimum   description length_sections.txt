=== MAIN ===

royalsocietypublishing.org/journal/rsta
Review
Article submitted to journal
Subject Areas:
machine learning, astrophysics
Keywords:
symbolic regression, minimum
description length
Author for correspondence:
Harry Desmond
e-mail: harry.desmond@port.ac.uk
(Exhaustive) Symbolic
Regression and model
selection by minimum
description length
Harry Desmond1
1Institute of Cosmology & Gravitation, University of Portsmouth, Dennis Sciama Building,
Portsmouth, PO1 3FX, United Kingdom

=== METHODOLOGY ===

science and beyond.
the inflaton field.

=== INTRODUCTION ===

A key activity in science is summarising observational data with functional fits. Either one wants a “fitting function” with which to propagate some correlation into another part of the analysis, or one wishes to learn the “law” that governs the data. Traditionally these two tasks have been tackled in different ways. The creation of fitting functions is normally done “by eye”:
one plots the data and estimates the types of operators and their composition that may give a good fit. This is supplemented with a trial-and-error step: if a given func- © The Authors. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/ by/4.0/, which permits unrestricted use, provided the original author and source are credited.
tional form does not give quite the right asymptotic behaviour, for example, another one is tried and the process iterated until a satisfactory fit is achieved. Such a procedure has on occasion been implemented also for learning “scientific laws”, the most notable example being Planck’s (and his antecedents’) discovery of (parts of) the blackbody function. More often however, the discovery of laws is achieved primarily by theory. Partially or completely independently of data, the theorist proposes principles or hypotheses that lead to certain functional relations between observables.
These functions are then tested on the data to assess the theory’s veracity.
This traditional approach has drawbacks. How can one be sure that the fitting functions one creates are in any sense optimal? One way is for the function to find a theoretical underpinning, as happened with the blackbody formula through quantum mechanics. But purely empirically there is no guarantee that any particular aspect of the function that may be important in applications of it—say its interpolation or extrapolation behaviour—is robust unless one has a quantitative assessment of the function’s quality relative to others. Even were such a quality metric available, assessing (all?) other possible functions seems infeasible. The same concerns apply to physical laws extracted empirically: the true features of the law may not be captured by an imperfect function generation procedure. The top-down approach (creating functions in an extra-empirical way before bringing in the data) of course has different concerns: in that case one must assess the reliability of theoretical arguments rather than a regression procedure. Might there be a way to greatly expand the capacity to learn laws directly from data, mitigating or even obviating these concerns?
Enter symbolic regression (SR), the machine learning (ML) framework for extracting functions directly from data. SR aims to automate and perfect the process described above. To explain it, it is useful to begin with the better-known form of regression, which I term regular or numerical.
Here one specifies a priori the functional form that one wants to fit and the regression is only over the numerical values of the function’s free parameters. SR generalises this procedure by bringing the functional form itself—the operators and their ordering—into the search space. This substantially increases the difficulty: not only is the search space much enlarged, but the lack of continuity between operators invalidates the use of techniques such as gradient descent that form the staple of parameter optimisation. But there are also clear advantages, most obviously that in regular regression the functional form one imposes is likely to be suboptimal or just plain wrong.
SR removes confirmation bias because the user is not required to make that important decision.
While regular regression has a long and venerable history, the advent of ML has introduced some additional “competitors” to SR. These are methods like neural networks, Gaussian processes and random forests which can capture the correlations present in a dataset to high fidelity by compounding very many simple functions. These methods excel at “mindless” regression and classification tasks: they can produce accurate predictions within the domain of their training set, but very rarely produce scientific insight into a system. This makes them best suited to summarising correlations that one wishes to treat entirely as “nuisance”, either because the underlying physics is already thoroughly well-known (e.g. the emergent behaviour of “baryonic physics” in galaxy evolution), or because it is not believed to be possible to learn basic science from them. SR, on the other hand, excels in cases where one does care about the functional form of a relation, perhaps because one believes it to reflect the meaningful physics governing the system. When successful, SR uncovers either the true equation that generated the data— if there is one—or else simply the best possible functional representation. That said, SR can also be valuable for constructing emulators without any demand for, or benefit to be gained from, interpretability: such symbolic emulators are highly portable (e.g. they do not require the neural network emulator’s constrained weights and biases), rapid to evaluate and potentially very accurate (e.g. [1]).
Exploring the parameter space is quite different when this includes operators. The most common method for generating trial functions is called a genetic algorithm (GA), which works by analogy with natural selection [2–4]. This begins by creating a population of functions with typically random examples. One then calculates the “fitness” of each one, which is its accuracy on the target dataset, and kills off the functions that fail some fitness cut. Then the next generation of functions is produced through mutation and crossover. A mutation changes one parts of a function, either a single operator or connected set of operators. A crossover mixes parts of two functions by swapping branches to produce two new functions. This new generation is then assessed against a stopping criterion—for example whether a function of sufficient accuracy has been produced, or a time limit—and if the criterion is not met the process is repeated in the hope of producing ever- better functions. Popular algorithms in this category are Operon [5], PySR [6] and DataModeler (a proprietary Mathematica add-on; [7]).
This review focuses on an alternative, non-stochastic approach to SR. A particular emphasis will be the model selection metric, i.e. the quantity used to determine how good trial functions are.
I will begin by describing the traditional way in which functions are evaluated (Sec. 2). I will then describe the approach of Exhaustive Symbolic Regression, which overhauls both the function generation and function assessment methodology (Sec. 3). Emphasis here is on the minimum description length selection metric (Sec. 4). I will then describe three astrophysical applications of ESR+MDL, showcasing its power on the expansion rate of the universe (Sec. 5(a)), galaxy dynamics (Sec. 5(b)) and cosmic inflation (Sec. 5(c)). I then describe future developments and conclude. Throughout the article log has base e.
2. Traditional function assessment
Suppose we have a set of trial functions (e.g. from a GA)—how should we score them? Let us consider again the analogy with regular regression. The analogues of candidate functions in this case are points in the space of the pre-defined function’s free parameters. In a Bayesian context these are scored by two metrics: the likelihood they give the data, and their prior probability.
These multiply by Bayes’ theorem, normalised by the evidence, to form the posterior. The best solution is the one that maximises the posterior, with an uncertainty given by a confidence interval of the posterior probability distribution. In a frequentist context one would use just the likelihood.
In SR, focusing on the likelihood or posterior produces an immediate problem. Now that we are allowed to vary operators we can produce arbitrarily complex functions, which typically means that they can be made arbitrarily accurate on the dataset in question. As an example, consider that one can perfectly fit any set of N datapoints with a polynomial of degree N − 1. But such extremely complex functions that maximise the likelihood are likely severely overfitted and hence extrapolate or generalise very poorly. This means that some measure of simplicity needs to be included in the function selection procedure: one wants some optimal trade-off between simplicity and accuracy.
The simplest way of doing this is (unfortunately) the approach traditionally taken in SR; this is to include simplicity as an incommensurate second objective in the regression. This is quantified with a “complexity” heuristic, for example the number of nodes in the function’s tree representation (i.e. the number of operators, parameters or variables in the function). Functions are then plotted on the 2D plane of accuracy (measured by maximum likelihood or posterior value, or its poor-man’s version mean square error) and complexity, producing a Pareto (two- objective) optimisation problem. There is a privileged set of functions on the Pareto plane, which are the most accurate for their complexity. These functions—one at each complexity value—form the Pareto front and are termed “Pareto optimal”: any other function has higher inaccuracy and/or complexity and is “Pareto dominated” by the optimum functions.
From this perspective all functions along the Pareto front are “the best”, and they cannot be compared. No metric is provided for how much gain in accuracy is required for an increment of complexity to be warranted. A second heuristic is therefore required for deciding where along the Pareto front to select the best function(s) from. One could eyeball the functions and pick the one deemed to be most attractive, one could decide one wants a function of a certain complexity, one could score the functions on both a training and test dataset and look for the complexity at which the accuracy of the latter starts to become significantly worse than that of the former (indicative of overfitting), or one could stipulate some function of accuracy and complexity to determine the final score. These procedures have no rigorous justification and are up to the user, yet may radically alter the outcome of the regression. We will see in the next section that a superior method exists.
3. Exhaustive Symbolic Regression
(a) Motivation and Operation
The traditional approach to SR outlined above faces two major challenges. First, a stochastic search has some completely unknown probability of failing to find any given good function. This may not be a serious issue if that probability is small in practice, but we will see in Sec. 3(b) that this is not the case. The failure probability is a function of the algorithm’s hyperparameters, but one does not know in advance how to set those to maximise efficacy for the dataset in question.
This makes SR results untrustworthy, as there may be any number of better-performing functions than those found. Second, judging equations on their Pareto-optimality depends crucially on the definitions of accuracy and complexity. Changing these will move functions around on the accuracy–complexity plane and change the ones that lie on the Pareto front. Most algorithms adopt mean square error (MSE) as the accuracy measure, but this only accurately describes the data likelihood if the uncertainties on the data points are Gaussian and constant. More importantly the complexity definition is largely arbitrary: some approaches use the number of operators, parameters and variables in the function, some use the depth of the function’s tree representation, while others adopt behavioural rather than structural measures like the degree to which the functions are nonlinear [8]. The incommensurability of accuracy and complexity then necessitates another unmotivated heuristic.
Exhaustive Symbolic Regression (ESR; [9]) is designed to overcome these problems. The first is solved by searching function space exhaustively, guaranteeing discovery of each and every good function, and the second by replacing complexity heuristics with a precise measure of the information content of the function called its description length.
To do an exhaustive search ESR generates every single possible function from some basis set of operators up to a maximum complexity, where complexity is defined as the number of nodes in the function’s tree representation. The operator basis set and maximum complexity are the only things that must be specified by the user, although the maximum complexity is typically set by the computational resources available. Generating all functions involves generating all possible tree templates, where the nodes are labelled by their arity (number of arguments), and decorating the trees by considering all permutations of the operators in the basis set with the correct arity. We then simplify the functions and remove duplicates using a set of function- comparison rules (tree reordering, parameter permutations, simplifications, reparametrisation invariance, parameter combinations). This establishes the unique functions, which are all inequivalent to each other and are representatives of sets of behaviourally identical but structurally different functions (e.g. θx and x/θ, where θ is a free parameter). Finally, we find the maximum-likelihood values of the free parameters appearing in the unique functions through nonlinear optimisation, and broadcast these results to all other members of the equivalent sets using the Jacobians of the transformations that relate them. Although the maximum likelihood values of all functions in such a set must be identical, they may possess different description lengths (see below), and hence our search for the lowest description length function ranges over these variants as well as the unique functions. Full details may be found in [9].
This is a computationally expensive procedure due to the huge number of possible functions at higher complexities. One’s computational budget therefore limits the complexity one can reach.
A typical limit is complexity 10, for which a full ESR run takes ∼200 CPU-hours (the scaling with complexity is exponential, so even greatly enhanced computational resources could not extend the maximum complexity by ≳ 1). This depends on the operator basis set (the more operators, the more functions at given complexity and hence the lower the maximum achievable complexity), and is necessarily approximate because the procedure is imperfectly parallelisable. Although the parameter fitting is embarrassingly parallelisable (each function is treated completely separately to all the others), the simplification steps must compare functions and hence cannot be done in isolation. Note that only the parameter fitting is dataset-specific: the function generation and simplification depend only on the operator set, allowing the user to benefit from publicly available pre-computed function sets [10]. This reduces runtime by more than a factor of 2. For reference, straight lines and power-laws have complexity 5, while the Navarro–Frenck–White (NFW; [11]) function describing halo density profiles (θ0(x(x + θ1)θ2 )− 1) has complexity 9: any function not
much more complex is within scope of ESR. The full ESR code is publicly available.1 (b) Benchmarking
To illustrate the advantage of a guaranteed search, this section demonstrates the unreliability of stochastic algorithms. We take perhaps the simplest benchmark dataset (feynman_I_6_2a) from the Penn Machine Learning Benchmarks dataset, as used in the SRBench competition [12]. This comprises 105 datapoints generated from an unknown univariate function without scatter. In addition to ESR we ran five state-of-the-art SR algorithms on the data: PySR, DataModeler [7], FFX [13], QLattice [14] and Operon. The test was conducted under exam conditions, with each algorithm given equal opportunity (full details in [9]).
Fig. 1 shows the Pareto front of MSE against complexity returned by each algorithm. The most noticeable feature is the cliff in MSE produced by ESR at complexity 7, which indicates a substantial improvement in the functional fit not seen by any other algorithm. The others can discover the most accurate functions up to complexity 5, but beyond that find only marginally improved solutions. On closer inspection it is seen that not only has ESR produced the best- fitting function, but in fact it has achieved the holy grail of SR which is to find the true function that generated the data. The best complexity-7 function is y = θ1θx2 0 , where θ0 = 0.6065 and
2π, suggesting that the data
θ1 = 0.3989. This is remarkably similar to θ0 = 1/ were drawn from a standard normal distribution. Inputting these exact values for the parameters 33, which is 0 to within machine precision. That ESR did not achieve this yields an MSE = 3 × 10−
directly is due to its numerical tolerance in the parameter optimisation, which also explains why slightly different MSE values are produced for the variants of the standard normal at complexities 8-10. The other SR algorithms gave no indication of this true structure, but simply produced approximate fitting functions. The exception to this is Operon, which does in fact produce a standard normal albeit overparametrised so that it appears at complexity 11.
e and θ1 = 1/

=== CONCLUSION ===

Symbolic regression is the machine learning method that codifies and automates the practice of empirical science, namely the creation of functions and equations describing data. While this is traditionally done “by eye”, SR is a task for computers—affording an enormous increase in processing power—if effective methods can be constructed.
SR is traditionally achieved by stochastic algorithms (e.g. genetic programming), with candidate functions assessed by locating the Pareto front in accuracy and complexity and then applying an additional ad hoc rule for selecting a single “best” function. I have argued that such methods face two serious challenges: 1) they have a significant probability of failing to find any given good function, and 2) the model selection procedure is unfounded in its arbitrary definition of complexity and unjustified heuristic for breaking the Pareto front degeneracy. To overcome the first I propose Exhaustive Symbolic Regression (ESR), and to overcome the second I propose the Minimum Description Length (MDL) principle. ESR implements an efficient algorithm for generating and optimising the parameters of all functions composed of a user-defined basis set of operators up to a maximum complexity, guaranteeing discovery of all good solutions. MDL measures functions’ quality with an information-theory-motivated metric that makes accuracy and simplicity commensurable, affording a principled one-dimensional ranking. It is essentially the Bayesian evidence plus a prior on functions that penalises those containing more, and more varied, operators. An alternative prior, based on a Katz back-off language model, instead penalises functions with combinations of operators that are rarer in a training set of equations.
I showcase ESR+MDL on three hot topics in astrophysics: the late-time expansion rate of the universe, the effective behaviour of gravity in galaxies and the potential of the field driving inflation. In each case, ESR discovers functions considerably superior to literature standards (the Friedmann equation, MOND and Starobinsky, quadratic and quartic inflation respectively), illustrating its ability to uncover effective symbolic representations of data purely empirically.
This bodes well for future discovery not only of optimal fitting functions, but, more ambitiously, of physical laws directly from data.
SR is only just starting to take off. The near future will see an extensive overhaul of the ESR algorithm, greatly improving its efficiency and capabilities. Synergy with genetic algorithms is also promising, combining their advantages in different regimes of complexity. At the same time there is a range of astrophysical (and other) fitting functions ripe for improvement. I suspect the golden age of symbolic machine learning not to be far away.
Acknowledgements. I thank Deaglan Bartlett, Pedro Ferreira, Gabriel Kronberger, Lukas Kammerer and Tomas Sousa for the collaborations on which this work is based. I am supported by a Royal Society University Research Fellowship (grant no. 211046).

=== REFERENCES ===

1. Sui C, Bartlett DJ, Pandey S, Desmond H, Ferreira PG, Wandelt BD. 2024 syren-new: Precise formulae for the linear and nonlinear matter power spectra with massive neutrinos and dynamical dark energy. arXiv e-prints p. arXiv:2410.14623. (10.48550/arXiv.2410.14623) 2. Turing AM. 1950 I.—COMPUTING MACHINERY AND INTELLIGENCE. Mind LIX, 433–460.
(10.1093/mind/LIX.236.433)
3. David E. 1989 Genetic Algorithms in Search, Optimization and Machine Learning. Addison-Wesley.
4. Haupt R, Haupt S. 2004 Practical genetic algorithms. Wyley 2nd edition.
5. Burlacu B, Kronberger G, Kommenda M. 2020 Operon C++: an efficient genetic programming framework for symbolic regression. pp. 1562–1570. (10.1145/3377929.3398099) 6. Cranmer M, Sanchez-Gonzalez A, Battaglia P, Xu R, Cranmer K, Spergel D, Ho S. 2020 Discovering Symbolic Models from Deep Learning with Inductive Biases. NeurIPS 2020.
7. Evolved Analytics LLC. Data Modeler 9.5.1. Evolved analytics LLC. URL: www.
evolved-analytics.com; 2021.
8. Vladislavleva EJ, Smits GF, den Hertog D. 2009 Order of Nonlinearity as a Complexity Measure for Models Generated by Symbolic Regression via Pareto Genetic Programming.
IEEE Transactions on Evolutionary Computation 13, 333–349. (10.1109/TEVC.2008.926486) 9. Bartlett DJ, Desmond H, Ferreira PG. 2024 Exhaustive Symbolic Regression. IEEE Transactions on Evolutionary Computation 28, 950–964. (10.1109/TEVC.2023.3280250) 10. Bartlett DJ, Desmond H, Ferreira PG. 2022 Exhaustive Symbolic Regression Function Sets.
(10.5281/zenodo.7339113)
11. Navarro JF, Frenk CS, White SDM. 1996 The Structure of Cold Dark Matter Halos. ApJ 462, 563. (10.1086/177173)
12. La Cava W, Orzechowski P, Burlacu B, Olivetti de França F, Virgolin M, Jin Y, Kommenda M, Moore JH. 2021 Contemporary Symbolic Regression Methods and their Relative Performance.
arXiv e-prints p. arXiv:2107.14351.
13. McConaghy T. 2011 pp. 235–260. In FFX: Fast, Scalable, Deterministic Symbolic Regression Technology, pp. 235–260. New York, NY: Springer New York. (10.1007/978-1-4614-1770-5_13) 14. René Broløs K, Vieira Machado M, Cave C, Kasak J, Stentoft-Hansen V, Galindo Batanero V, Jelen T, Wilstrup C. 2021 An Approach to Symbolic Regression Using Feyn. arXiv e-prints p.
arXiv:2104.05417. (10.48550/arXiv.2104.05417)
15. Cranmer M. 2020 PySR: Fast & Parallelized Symbolic Regression in Python/Julia.
(10.5281/zenodo.4041459)
16. Rissanen J. 1978 Modeling by shortest data description. Automatica 14, 465–471.
(https://doi.org/10.1016/0005-1098(78)90005-5)
17. Grünwald P, Roos T. 2019 Minimum Description Length Revisited. arXiv e-prints p.
18. Cover TM, Thomas JA. 1991 Elements of Information Theory. Wiley 2nd edition.
19. Bartlett DJ, Desmond H, Ferreira PG. 2023 Priors for symbolic regression. arXiv e-prints p.
arXiv:2304.06333. (10.48550/arXiv.2304.06333)
20. Katz SM. 1987 Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE Trans. Acoust. Speech Signal Process. 35, 400–401.
21. Moresco M et al.. 2022 Unveiling the Universe with emerging cosmological probes. Living Reviews in Relativity 25, 6. (10.1007/s41114-022-00040-z) 22. Scolnic D et al.. 2021 The Pantheon+ Analysis: The Full Dataset and Light-Curve Release.
arXiv e-prints p. arXiv:2112.03863.
23. Desmond H, Bartlett DJ, Ferreira PG. 2023 On the functional form of the radial acceleration relation. MNRAS 521, 1817–1831. (10.1093/mnras/stad597) 24. Milgrom M. 1983a A modification of the Newtonian dynamics as a possible alternative to the hidden mass hypothesis. ApJ 270, 365–370. (10.1086/161130) 25. Milgrom M. 1983b A Modification of the Newtonian Dynamics - Implications for Galaxy Systems. ApJ 270, 384. (10.1086/161132)
26. Milgrom M. 1983c A modification of the Newtonian dynamics - Implications for galaxies. ApJ 270, 371–389. (10.1086/161131)
27. Desmond H. 2025 Modified Newtonian Dynamics: Observational Successes and Failures.
arXiv e-prints p. arXiv:2505.21638. (10.48550/arXiv.2505.21638) 28. Lelli F, McGaugh SS, Schombert JM, Pawlowski MS. 2017 One Law to Rule Them All: The Radial Acceleration Relation of Galaxies. ApJ 836, 152. (10.3847/1538-4357/836/2/152) 29. Desmond H. 2023 The underlying radial acceleration relation. MNRAS 526, 3342–3351.
(10.1093/mnras/stad2762)
30. Stiskalek R, Desmond H. 2023 On the fundamentality of the radial acceleration relation for late-type galaxy dynamics. MNRAS 525, 6130–6145. (10.1093/mnras/stad2675) 31. Mistele T, McGaugh S, Lelli F, Schombert J, Li P. 2024 Radial acceleration relation of galaxies with joint kinematic and weak-lensing data. JCAP 2024, 020. (10.1088/1475- 7516/2024/04/020)
32. Sousa T, Bartlett DJ, Desmond H, Ferreira PG. 2024 Optimal inflationary potentials. PRD 109, 083524. (10.1103/PhysRevD.109.083524)
33. Martin J, Ringeval C, Vennin V. 2013 Encyclopaedia Inflationaris. arXiv e-prints p.
arXiv:1303.3787. (10.48550/arXiv.1303.3787)

=== RESULTS ===

(10.1051/0004-6361/201833887)
35. Galloni G, Bartolo N, Matarrese S, Migliaccio M, Ricciardone A, Vittorio N. 2023 Updated constraints on amplitude and tilt of the tensor primordial spectrum. JCAP 2023, 062.
(10.1088/1475-7516/2023/04/062)
36. Burlacu B. 2023 GECCO’2022 Symbolic Regression Competition: Post-Analysis of the Operon Framework. In Proceedings of the Companion Conference on Genetic and Evolutionary Computation GECCO ’23 Companion p. 2412–2419 New York, NY, USA. Association for Computing Machinery. (10.1145/3583133.3596390)
37. Schechter P. 1976 An analytic expression for the luminosity function for galaxies.. ApJ 203, 297–306. (10.1086/154079)

