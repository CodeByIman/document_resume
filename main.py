#!/usr/bin/env python3
"""
Script principal pour le t√©l√©chargement et l'extraction de texte de papers arXiv
Fonctionnalit√©s:
- T√©l√©chargement de PDFs depuis arXiv
- Extraction et nettoyage du texte des PDFs t√©l√©charg√©s
- Extraction des sections, abstract, mots-cl√©s
"""

import sys
import json
import logging
from pathlib import Path
import glob
import os

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(str(Path(__file__).parent))

from downloaders.arxiv_downloader import ArxivDownloader
from extractors.pdf_extractor import PDFExtractor
from extractors.text_cleaner import TextCleaner


def setup_logging():
    """Configure le logging"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('main_processing.log')
        ]
    )


def download_and_extract_paper(url, output_dir="downloads"):
    """
    T√©l√©charge un paper et extrait son contenu texte
    
    Args:
        url: URL arXiv du paper
        output_dir: R√©pertoire de t√©l√©chargement
    
    Returns:
        dict: Informations sur le traitement (m√©tadonn√©es, chemins fichiers, etc.)
    """
    print(f"\n{'='*80}")
    print(f"üöÄ TRAITEMENT COMPLET D'UN PAPER ARXIV")
    print(f"{'='*80}")
    print(f"üìé URL: {url}")
    
    result = {
        'url': url,
        'success': False,
        'pdf_path': None,
        'text_files': {},
        'metadata': {},
        'error': None
    }
    
    try:
        # 1. Initialiser les modules
        downloader = ArxivDownloader()
        pdf_extractor = PDFExtractor()
        text_cleaner = TextCleaner()
        
        # 2. V√©rifier que l'URL est valide
        if not downloader.can_handle(url):
            raise ValueError(f"URL non support√©e: {url}")
        
        print(f"‚úÖ URL arXiv valide d√©tect√©e")
        
        # 3. R√©cup√©rer les m√©tadonn√©es
        print(f"\nüîç R√©cup√©ration des m√©tadonn√©es...")
        metadata = downloader.get_metadata(url)
        result['metadata'] = metadata
        
        print(f"üìù Titre: {metadata.get('title', 'Non trouv√©')}")
        print(f"üë• Auteurs: {', '.join(metadata.get('authors', []))}")
        print(f"üìÖ Date: {metadata.get('published_date', 'Non trouv√©')}")
        
        # 4. T√©l√©charger le PDF
        print(f"\nüì• T√©l√©chargement du PDF...")
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        filename = downloader.generate_filename(url, metadata)
        pdf_path = output_path / filename
        
        download_result = downloader.download(url, str(pdf_path))
        if not download_result['success']:
            raise Exception(f"√âchec du t√©l√©chargement: {download_result.get('error', 'Erreur inconnue')}")
        
        result['pdf_path'] = str(pdf_path)
        print(f"‚úÖ PDF t√©l√©charg√©: {pdf_path}")
        
        # 5. Extraire le texte du PDF
        print(f"\nüîß Extraction du texte...")
        extraction_result = pdf_extractor.extract_text(str(pdf_path))
        
        # V√©rifier le format de retour (peut √™tre juste du texte ou un dict)
        if isinstance(extraction_result, dict):
            if 'success' in extraction_result and not extraction_result['success']:
                raise Exception(f"√âchec de l'extraction: {extraction_result.get('error', 'Erreur inconnue')}")
            raw_text = extraction_result.get('text', extraction_result.get('content', str(extraction_result)))
            method_used = extraction_result.get('method_used', 'm√©thode inconnue')
        else:
            # Si c'est directement du texte
            raw_text = str(extraction_result)
            method_used = 'extraction directe'
        
        if not raw_text or len(raw_text.strip()) < 10:
            raise Exception("Texte extrait vide ou trop court")
            
        print(f"‚úÖ Texte extrait ({len(raw_text)} caract√®res) avec: {method_used}")
        
        # 6. Nettoyer le texte
        print(f"\nüßπ Nettoyage du texte...")
        cleaned_text = text_cleaner.clean_text(raw_text)
        
        stats_before = text_cleaner.get_text_stats(raw_text)
        stats_after = text_cleaner.get_text_stats(cleaned_text)
        
        print(f"üìä Avant: {stats_before['words']} mots, {stats_before['lines']} lignes")
        print(f"üìä Apr√®s: {stats_after['words']} mots, {stats_after['lines']} lignes")
        
        # 7. Extraire les diff√©rentes parties
        print(f"\nüìë Extraction des sections...")
        sections = text_cleaner.extract_sections(cleaned_text)
        
        print(f"\nüìÑ Extraction de l'abstract...")
        abstract = text_cleaner.extract_abstract(cleaned_text)
        
        print(f"\nüè∑Ô∏è Extraction des mots-cl√©s...")
        keywords = text_cleaner.extract_keywords(cleaned_text)
        
        # 8. Sauvegarder tous les fichiers
        print(f"\nüíæ Sauvegarde des r√©sultats...")
        base_name = pdf_path.stem
        
        # Texte complet nettoy√©
        clean_text_path = output_path / f"{base_name}_cleaned.txt"
        with open(clean_text_path, 'w', encoding='utf-8') as f:
            f.write(cleaned_text)
        result['text_files']['cleaned'] = str(clean_text_path)
        print(f"‚úÖ Texte nettoy√©: {clean_text_path.name}")
        
        # Abstract
        if abstract:
            abstract_path = output_path / f"{base_name}_abstract.txt"
            with open(abstract_path, 'w', encoding='utf-8') as f:
                f.write(abstract)
            result['text_files']['abstract'] = str(abstract_path)
            print(f"‚úÖ Abstract: {abstract_path.name}")
        
        # Sections
        if sections:
            sections_path = output_path / f"{base_name}_sections.txt"
            with open(sections_path, 'w', encoding='utf-8') as f:
                for section_name, section_content in sections.items():
                    if section_content:
                        f.write(f"=== {section_name.upper()} ===\n\n")
                        f.write(section_content)
                        f.write("\n\n")
            result['text_files']['sections'] = str(sections_path)
            print(f"‚úÖ Sections: {sections_path.name}")
        
        # M√©tadonn√©es compl√®tes + r√©sultats d'extraction
        metadata_path = output_path / f"{base_name}_metadata.json"
        full_metadata = {
            'arxiv_metadata': metadata,
            'extraction_info': {
                'method_used': extraction_result['method_used'],
                'pages_processed': extraction_result.get('pages', 0),
                'text_stats': stats_after,
                'abstract_found': bool(abstract),
                'keywords_found': len(keywords) if keywords else 0,
                'sections_found': list(sections.keys()) if sections else []
            },
            'files_generated': result['text_files']
        }
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(full_metadata, f, indent=2, ensure_ascii=False)
        result['text_files']['metadata'] = str(metadata_path)
        print(f"‚úÖ M√©tadonn√©es: {metadata_path.name}")
        
        result['success'] = True
        print(f"\nüéâ Traitement complet termin√© avec succ√®s!")
        
        return result
        
    except Exception as e:
        error_msg = f"Erreur lors du traitement: {str(e)}"
        print(f"\n‚ùå {error_msg}")
        logging.error(f"Erreur traitement {url}: {str(e)}", exc_info=True)
        result['error'] = error_msg
        return result


def extract_existing_pdfs(downloads_dir="downloads"):
    """
    Extrait le texte de tous les PDFs d√©j√† pr√©sents dans le dossier downloads
    
    Args:
        downloads_dir: R√©pertoire contenant les PDFs
    """
    print(f"\n{'='*80}")
    print(f"üîç EXTRACTION DES PDFS EXISTANTS")
    print(f"{'='*80}")
    
    downloads_path = Path(downloads_dir)
    if not downloads_path.exists():
        print(f"‚ùå Le dossier {downloads_dir} n'existe pas.")
        return
    
    # Chercher tous les PDFs
    pdf_files = list(downloads_path.glob("*.pdf"))
    
    if not pdf_files:
        print(f"üìÅ Aucun PDF trouv√© dans {downloads_dir}")
        return
    
    print(f"üìö {len(pdf_files)} PDF(s) trouv√©(s):")
    for pdf_file in pdf_files:
        print(f"  üìÑ {pdf_file.name}")
    
    # Initialiser les extracteurs
    pdf_extractor = PDFExtractor()
    text_cleaner = TextCleaner()
    
    processed_count = 0
    
    for pdf_file in pdf_files:
        print(f"\n{'‚îÄ'*60}")
        print(f"üîß Traitement de: {pdf_file.name}")
        
        try:
            # V√©rifier si les fichiers de texte existent d√©j√†
            base_name = pdf_file.stem
            cleaned_text_file = downloads_path / f"{base_name}_cleaned.txt"
            
            if cleaned_text_file.exists():
                print(f"‚è≠Ô∏è Fichier texte d√©j√† existant, passage au suivant...")
                continue
            
            # Extraire le texte
            print(f"  üîß Extraction du texte...")
            extraction_result = pdf_extractor.extract_text(str(pdf_file))
            
            # G√©rer diff√©rents formats de retour
            if isinstance(extraction_result, dict):
                if 'success' in extraction_result and not extraction_result['success']:
                    print(f"  ‚ùå √âchec extraction: {extraction_result.get('error', 'Erreur inconnue')}")
                    continue
                raw_text = extraction_result.get('text', extraction_result.get('content', str(extraction_result)))
            else:
                # Si c'est directement du texte
                raw_text = str(extraction_result)
            
            if not raw_text or len(raw_text.strip()) < 10:
                print(f"  ‚ùå Texte extrait vide ou trop court")
                continue
            
            print(f"  ‚úÖ {len(raw_text)} caract√®res extraits")
            
            # Nettoyer le texte
            print(f"  üßπ Nettoyage...")
            cleaned_text = text_cleaner.clean_text(raw_text)
            
            # Extraire les parties
            abstract = text_cleaner.extract_abstract(cleaned_text)
            sections = text_cleaner.extract_sections(cleaned_text)
            keywords = text_cleaner.extract_keywords(cleaned_text)
            
            # Sauvegarder
            print(f"  üíæ Sauvegarde...")
            
            # Texte nettoy√©
            with open(cleaned_text_file, 'w', encoding='utf-8') as f:
                f.write(cleaned_text)
            print(f"    ‚úÖ {cleaned_text_file.name}")
            
            # Abstract
            if abstract:
                abstract_file = downloads_path / f"{base_name}_abstract.txt"
                with open(abstract_file, 'w', encoding='utf-8') as f:
                    f.write(abstract)
                print(f"    ‚úÖ {abstract_file.name}")
            
            # Sections
            if sections:
                sections_file = downloads_path / f"{base_name}_sections.txt"
                with open(sections_file, 'w', encoding='utf-8') as f:
                    for section_name, section_content in sections.items():
                        if section_content:
                            f.write(f"=== {section_name.upper()} ===\n\n")
                            f.write(section_content)
                            f.write("\n\n")
                print(f"    ‚úÖ {sections_file.name}")
            
            processed_count += 1
            print(f"  ‚úÖ Traitement termin√©")
            
        except Exception as e:
            print(f"  ‚ùå Erreur: {str(e)}")
            logging.error(f"Erreur extraction PDF {pdf_file}: {str(e)}", exc_info=True)
    
    print(f"\nüéâ {processed_count} PDF(s) trait√©(s) avec succ√®s!")


def interactive_menu():
    """Menu interactif pour choisir les actions"""
    while True:
        print(f"\n{'='*60}")
        print(f"üìö GESTIONNAIRE DE PAPERS ARXIV")
        print(f"{'='*60}")
        print(f"1. üì• T√©l√©charger et extraire un nouveau paper")
        print(f"2. üîß Extraire le texte des PDFs existants")
        print(f"3. üìã Lister les fichiers dans downloads/")
        print(f"4. üß™ Tests des modules")
        print(f"5. ‚ùå Quitter")
        
        choice = input("\nüëâ Votre choix (1-5): ").strip()
        
        if choice == "1":
            url = input("üîó URL arXiv du paper: ").strip()
            if url:
                download_and_extract_paper(url)
            else:
                print("‚ùå URL vide!")
        
        elif choice == "2":
            extract_existing_pdfs()
        
        elif choice == "3":
            list_downloads()
        
        elif choice == "4":
            run_tests()
        
        elif choice == "5":
            print("üëã Au revoir!")
            break
        
        else:
            print("‚ùå Choix invalide!")


def list_downloads():
    """Liste tous les fichiers dans le dossier downloads"""
    print(f"\nüìÅ Contenu du dossier downloads/:")
    print("‚îÄ" * 60)
    
    downloads_path = Path("downloads")
    if not downloads_path.exists():
        print("‚ùå Le dossier downloads/ n'existe pas encore.")
        return
    
    files = list(downloads_path.iterdir())
    if not files:
        print("üìÇ Dossier vide")
        return
    
    # Grouper par type
    pdfs = [f for f in files if f.suffix == '.pdf']
    texts = [f for f in files if f.suffix == '.txt']
    jsons = [f for f in files if f.suffix == '.json']
    others = [f for f in files if f.suffix not in ['.pdf', '.txt', '.json']]
    
    if pdfs:
        print(f"\nüìÑ PDFs ({len(pdfs)}):")
        for pdf in sorted(pdfs):
            size = pdf.stat().st_size / 1024  # KB
            print(f"  {pdf.name} ({size:.1f} KB)")
    
    if texts:
        print(f"\nüìù Fichiers texte ({len(texts)}):")
        for txt in sorted(texts):
            print(f"  {txt.name}")
    
    if jsons:
        print(f"\nüìã M√©tadonn√©es ({len(jsons)}):")
        for json_file in sorted(jsons):
            print(f"  {json_file.name}")
    
    if others:
        print(f"\n‚ùì Autres fichiers ({len(others)}):")
        for other in sorted(others):
            print(f"  {other.name}")


def run_tests():
    """Ex√©cuter les tests de base des modules"""
    print(f"\nüß™ TESTS DES MODULES")
    print("=" * 50)
    
    # Test du t√©l√©chargeur
    print(f"\n1. Test ArxivDownloader...")
    try:
        downloader = ArxivDownloader()
        test_url = "https://arxiv.org/abs/1706.03762"
        can_handle = downloader.can_handle(test_url)
        print(f"   ‚úÖ Peut g√©rer {test_url}: {can_handle}")
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
    
    # Test de l'extracteur PDF
    print(f"\n2. Test PDFExtractor...")
    try:
        pdf_extractor = PDFExtractor()
        # Chercher un PDF de test
        downloads_path = Path("downloads")
        if downloads_path.exists():
            pdf_files = list(downloads_path.glob("*.pdf"))
            if pdf_files:
                test_pdf = pdf_files[0]
                is_valid = pdf_extractor.is_valid_pdf(str(test_pdf))
                print(f"   ‚úÖ {test_pdf.name} est valide: {is_valid}")
            else:
                print(f"   ‚è≠Ô∏è Aucun PDF de test disponible")
        else:
            print(f"   ‚è≠Ô∏è Dossier downloads/ inexistant")
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
    
    # Test du nettoyeur de texte
    print(f"\n3. Test TextCleaner...")
    try:
        text_cleaner = TextCleaner()
        test_text = "   This is a test.   \n\n\n  Another line.  "
        cleaned = text_cleaner.clean_text(test_text)
        print(f"   ‚úÖ Texte nettoy√©: '{cleaned}'")
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")


def main():
    """Fonction principale"""
    setup_logging()
    
    print("üöÄ GESTIONNAIRE DE PAPERS ARXIV")
    print("T√©l√©chargement et extraction de texte")
    
    # V√©rifier les arguments de ligne de commande
    if len(sys.argv) > 1:
        if sys.argv[1] == "--extract-existing":
            # Extraire les PDFs existants
            extract_existing_pdfs()
        elif sys.argv[1] == "--interactive":
            # Mode interactif
            interactive_menu()
        elif sys.argv[1].startswith("http"):
            # URL fournie directement
            url = sys.argv[1]
            download_and_extract_paper(url)
        else:
            print("Usage:")
            print("  python main.py                    # Mode interactif")
            print("  python main.py --interactive      # Mode interactif")
            print("  python main.py --extract-existing # Extraire PDFs existants")
            print("  python main.py <url_arxiv>        # T√©l√©charger un paper")
    else:
        # Mode interactif par d√©faut
        interactive_menu()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã Interruption par l'utilisateur. Au revoir!")
    except ImportError as e:
        print(f"‚ùå Erreur d'import: {e}")
        print("\nAssurez-vous que tous les modules sont pr√©sents:")
        print("  downloaders/arxiv_downloader.py")
        print("  extractors/pdf_extractor.py")
        print("  extractors/text_cleaner.py")
    except Exception as e:
        print(f"‚ùå Erreur inattendue: {e}")
        logging.error(f"Erreur inattendue dans main: {str(e)}", exc_info=True)